{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from rich import print\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio as ipy_audio\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import permutations, product\n",
    "from typing import Dict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midiutils.read import get_audio, get_symbol_string\n",
    "from mogra.datatypes import Swar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read MIDI Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_file = \"midiutils/samples/Bahar.mid\"  # root 49\n",
    "midi_file = \"midiutils/samples/MiyankiMalhar.mid\"  # root 61\n",
    "audio, sr = get_audio(midi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipy_audio(data=audio[:1500000], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = int(input(\"set root note (C = 60)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syms = get_symbol_string(midi_file, root)\n",
    "plt.hist(syms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = input(\"type list of allowed symbols (empty = include all)\")\n",
    "if allowed == \"\": allowed = \"\".join(set(syms))\n",
    "syms = [ss for ss in syms if ss in allowed]\n",
    "syms_list = [syms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Transcribed Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_file = \"transcriptions/KaushikDhwani_[oQuyV_tsNs].txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(transcription_file, \"r\") as fp:\n",
    "    data = fp.readlines()\n",
    "\n",
    "syms_list = [ll.strip().replace(\" \",\"\") for ll in data if (ll[0]!=\"#\" and len(ll)>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKOV_UNSEEN_SMOOTHING = np.log(1e-10)\n",
    "MARKOV_EVAL_FRACTION = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMarkov:\n",
    "    def __init__(self, order: int) -> None:\n",
    "        self.order = order\n",
    "        self.transition_counts = defaultdict(Counter)\n",
    "        self.total_counts = Counter()\n",
    "        self.transition_probs = {}\n",
    "    \n",
    "    def compute_probs(self):\n",
    "        self.states = set([s[0] for s in self.total_counts.keys()]).union(set([\"!\", \"|\"]))\n",
    "        for state, next_states in self.transition_counts.items():\n",
    "            total = self.total_counts[state]\n",
    "            self.transition_probs[state] = {k: v / total for k, v in next_states.items()}\n",
    "        \n",
    "    def fit(self, train_sequence: list):\n",
    "        for ii in range(len(train_sequence) - self.order):\n",
    "            state = tuple(train_sequence[ii:ii+self.order])\n",
    "            self.total_counts[state] += 1\n",
    "            next_state = train_sequence[ii+self.order]\n",
    "            self.transition_counts[state][next_state] += 1\n",
    "        \n",
    "        self.compute_probs()\n",
    "    \n",
    "    def calculate_log_likelihood(self, eval_sequences) -> Dict:\n",
    "        \"\"\" Function to calculate log-likelihood of the sequence under the fitted model\n",
    "        \"\"\"\n",
    "        all_log_likelihoods = []\n",
    "        for eval_sequence in eval_sequences:\n",
    "            log_likelihood_array = np.zeros(len(eval_sequence) - self.order)\n",
    "            for ii in range(self.order, len(eval_sequence)):\n",
    "                state = tuple(eval_sequence[ii-self.order:ii])\n",
    "                next_state = eval_sequence[ii]\n",
    "                if (state in self.transition_probs) and (next_state in self.transition_probs[state]):\n",
    "                    log_likelihood_array[ii-self.order] = np.log(self.transition_probs[state][next_state])\n",
    "                else:\n",
    "                    log_likelihood_array[ii-self.order] = MARKOV_UNSEEN_SMOOTHING  # Smoothing for unseen transitions\n",
    "            all_log_likelihoods.extend(log_likelihood_array)\n",
    "        \n",
    "        return {\n",
    "            \"log_likelihood\": sum(all_log_likelihoods),\n",
    "            \"perplexity\": np.exp(-np.mean(all_log_likelihoods))\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each subsequent order carries this fraction of the weight of the current order\n",
    "# if this = 0.5 and order = 3, then the weightages of jump matrices of order 1, 2, 3, = np.array([1, 0.5, 0.25])/1.75\n",
    "ORDER_DISCOUNTING_FACTOR = 0.5\n",
    "\n",
    "class JumpMarkov:\n",
    "    def __init__(self, order: int) -> None:\n",
    "        self.order = order\n",
    "        self.transition_counts = {oo: defaultdict(Counter) for oo in range(1, order+1)}\n",
    "        self.total_counts = {oo: Counter() for oo in range(1, order+1)}\n",
    "        self.discounting_normalizer = (1-ORDER_DISCOUNTING_FACTOR**self.order)/(1-ORDER_DISCOUNTING_FACTOR)\n",
    "        self.transition_probs = {oo: defaultdict(Counter) for oo in range(1, order+1)}\n",
    "    \n",
    "    def compute_probs(self):\n",
    "        self.states = set(self.total_counts[1].keys()).union(set([\"!\", \"|\"]))\n",
    "        for state in self.states:\n",
    "            for oo in range(1, self.order+1):\n",
    "                total = self.total_counts[oo][state]\n",
    "                self.transition_probs[oo][state] += {k: v / total for k, v in self.transition_counts[oo][state].items()}\n",
    "    \n",
    "    def fit(self, train_sequence: list):\n",
    "        for oo in range(1, self.order+1):\n",
    "            for ii in range(self.order, len(train_sequence)):\n",
    "                state = train_sequence[ii-oo]\n",
    "                self.total_counts[oo][state] += 1\n",
    "                next_state = train_sequence[ii]\n",
    "                self.transition_counts[oo][state][next_state] += 1\n",
    "        \n",
    "        self.compute_probs()\n",
    "    \n",
    "    def calculate_log_likelihood(self, eval_sequences):\n",
    "        \"\"\" Function to calculate log-likelihood of the sequence under the fitted model\n",
    "        \"\"\"\n",
    "        # TODO(neeraja): something's wrong here!\n",
    "        all_log_likelihoods = []\n",
    "        for eval_sequence in eval_sequences:\n",
    "            log_likelihood_array = np.zeros(len(eval_sequence) - self.order)\n",
    "            mult = 1\n",
    "            for oo in range(1, self.order+1):\n",
    "                for ii in range(self.order, len(eval_sequence)):\n",
    "                    state = eval_sequence[ii-oo]\n",
    "                    next_state = eval_sequence[ii]\n",
    "                    if (state in self.transition_probs[oo]) and (next_state in self.transition_probs[oo][state]):\n",
    "                        log_likelihood_array[ii-self.order] += mult * np.log(self.transition_probs[oo][state][next_state])\n",
    "                    else:\n",
    "                        log_likelihood_array[ii-self.order] += mult * MARKOV_UNSEEN_SMOOTHING  # Smoothing for unseen transitions\n",
    "            \n",
    "                mult *= ORDER_DISCOUNTING_FACTOR\n",
    "            \n",
    "            log_likelihood_array = log_likelihood_array/self.discounting_normalizer\n",
    "            all_log_likelihoods.extend(log_likelihood_array)\n",
    "        \n",
    "        return {\n",
    "            \"log_likelihood\": sum(all_log_likelihoods),\n",
    "            \"perplexity\": np.exp(-np.mean(all_log_likelihoods))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AIC and BIC for model comparison\n",
    "def calculate_aic_bic(log_likelihood, num_params, n):\n",
    "    aic = 2 * num_params - 2 * log_likelihood\n",
    "    bic = np.log(n) * num_params - 2 * log_likelihood\n",
    "    return aic, bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit tests\n",
    "\n",
    "strain = \"abababababababab\"\n",
    "stest1 = [\"aaaaaaaaaaaaaaaa\"]\n",
    "stest2 = [\"babababababababa\"]\n",
    "\n",
    "sm = SimpleMarkov(1)\n",
    "sm.fit(strain)\n",
    "p1 = sm.calculate_log_likelihood(stest1)[\"perplexity\"]\n",
    "sm = SimpleMarkov(2)\n",
    "sm.fit(strain)\n",
    "p2 = sm.calculate_log_likelihood(stest1)[\"perplexity\"]\n",
    "assert int(p1) == int(p2)\n",
    "\n",
    "jm = JumpMarkov(1)\n",
    "jm.fit(strain)\n",
    "p3 = jm.calculate_log_likelihood(stest1)[\"perplexity\"]\n",
    "jm = JumpMarkov(2)\n",
    "jm.fit(strain)\n",
    "p4 = jm.calculate_log_likelihood(stest1)[\"perplexity\"]\n",
    "assert p4 < p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train val split\n",
    "if len(syms_list) == 1:\n",
    "    syms = syms_list[0]\n",
    "    eval_begin = int(len(syms)*(1-MARKOV_EVAL_FRACTION))\n",
    "    sequences_train = [syms[:eval_begin]]\n",
    "    sequences_eval = [syms[eval_begin:]]\n",
    "else:\n",
    "    np.random.seed(256)\n",
    "    shuffled_list = deepcopy(syms_list)\n",
    "    np.random.shuffle(shuffled_list)\n",
    "    eval_begin = int(len(shuffled_list)*(1-MARKOV_EVAL_FRACTION))\n",
    "    sequences_train = shuffled_list[:eval_begin]\n",
    "    sequences_eval = shuffled_list[eval_begin:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Markov models of order 1, 2, and 3\n",
    "models = {}\n",
    "log_likelihoods = {}\n",
    "perplexities = {}\n",
    "orders = [\"1s\", \"2s\", \"3s\", \"1j\", \"2j\", \"3j\"]\n",
    "for order in orders:\n",
    "    if order[1] == \"s\":\n",
    "        sm = SimpleMarkov(order=int(order[0]))\n",
    "        for strain in sequences_train:\n",
    "            sm.fit(strain)\n",
    "        models[order] = sm\n",
    "    elif order[1] == \"j\":\n",
    "        jm = JumpMarkov(order=int(order[0]))\n",
    "        for strain in sequences_train:\n",
    "            jm.fit(strain)\n",
    "        models[order] = jm\n",
    "    eval = models[order].calculate_log_likelihood(sequences_eval)\n",
    "    log_likelihoods[order] = eval[\"log_likelihood\"]\n",
    "    perplexities[order] = eval[\"perplexity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate them\n",
    "aic = {}\n",
    "bic = {}\n",
    "n = len(syms)\n",
    "for order in orders:\n",
    "    num_params = sum(len(next_states) for next_states in models[order].transition_probs.values())\n",
    "    aic[order], bic[order] = calculate_aic_bic(log_likelihoods[order], num_params, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "print(f\"Order of Model:\\t\\tLog-Likelihood\\tPerplexity\\tAIC\\tBIC\")\n",
    "for order in orders:\n",
    "    print(f\"{order}\\t{log_likelihoods[order]}\\t{perplexities[order]}\\t{aic[order]}\\t{aic[order]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordering(state):\n",
    "    if state == \"!\":\n",
    "        return 0\n",
    "    elif state == \"|\":\n",
    "        return 100\n",
    "    else:\n",
    "        return Swar[state].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix for the 1st order model\n",
    "sm1 = models[\"1s\"]\n",
    "sorted_states = sorted(sm1.states, key=ordering)\n",
    "sm1_transition_map = np.zeros((len(sorted_states), len(sorted_states)))\n",
    "for tup in sm1.transition_probs:\n",
    "    sm1_transition_map[sorted_states.index(tup[0])] = [\n",
    "        sm1.transition_probs[tup].get(ss, np.exp(MARKOV_UNSEEN_SMOOTHING))\n",
    "        for ss in sorted_states\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sm1_transition_map)\n",
    "# plt.xticks(ticks=np.arange(len(sorted_states)), labels=sorted_states, rotation=90)\n",
    "# plt.yticks(ticks=np.arange(len(sorted_states)), labels=sorted_states)\n",
    "plt.clim(0, 1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icm-shruti-analysis-XL3d-GDY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
