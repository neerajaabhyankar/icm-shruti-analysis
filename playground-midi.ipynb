{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mido\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio as ipy_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = mido.MidiFile(\"midi-samples/Bahar.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = mid.tracks[0]\n",
    "\n",
    "# # meta\n",
    "# for ii, mm in enumerate(track):\n",
    "#     if type(mm) != mido.messages.messages.Message:\n",
    "#         print(mm)\n",
    "\n",
    "# # other signals\n",
    "# for ii, mm in enumerate(track):\n",
    "#     if type(mm) == mido.messages.messages.Message:\n",
    "#         if mm.type != \"note_on\":\n",
    "#             print(mm)\n",
    "\n",
    "track_notes = []\n",
    "for ii, mm in enumerate(track):\n",
    "    if type(mm) == mido.messages.messages.Message:\n",
    "        if mm.type == \"note_on\":\n",
    "            track_notes.append(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_length = mid.length\n",
    "midi_ticks_per_beat = mid.ticks_per_beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "sr = 22050  # Sampling rate for audio\n",
    "velocity_scaling = 127.0  # Maximum MIDI velocity\n",
    "note_on_velocity_threshold = 0  # Threshold to consider a note_on event as actually on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert MIDI note to frequency\n",
    "def midi_to_freq(midi_note):\n",
    "    return 440.0 * 2**((midi_note - 69) / 12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank audio array\n",
    "audio_length = int(mido.tick2second(midi_length, midi_ticks_per_beat, 500000) * sr)\n",
    "audio = np.zeros(audio_length*sr)\n",
    "# Create a blank symbolic array\n",
    "# TODO(neeraja): take notes equi-spaced in time\n",
    "nts = np.array([0,]*len(track_notes))\n",
    "\n",
    "\n",
    "# Time tracking\n",
    "current_time = 0\n",
    "\n",
    "for ii, msg in enumerate(track_notes):\n",
    "    assert msg.type == \"note_on\"\n",
    "    nts[ii] = msg.note\n",
    "    \n",
    "    # Calculate time in seconds and samples\n",
    "    note_time = mido.tick2second(msg.time, midi_ticks_per_beat, 500000)\n",
    "    note_samples = int(note_time * sr)\n",
    "\n",
    "    # Calculate the start and end sample indices\n",
    "    start_sample = current_time\n",
    "    end_sample = current_time + note_samples\n",
    "\n",
    "    if msg.velocity >= note_on_velocity_threshold:  # Note on event\n",
    "        freq = midi_to_freq(msg.note)\n",
    "        duration = (note_samples / sr)\n",
    "\n",
    "        # Generate a sine wave for the note\n",
    "        t = np.linspace(0, duration, note_samples, False)\n",
    "        wave = 0.5 * np.sin(2 * np.pi * freq * t) * (msg.velocity / velocity_scaling)\n",
    "\n",
    "        # Add the generated wave to the audio array\n",
    "        assert len(wave) == end_sample - start_sample\n",
    "        audio[start_sample:start_sample+len(wave)] += wave\n",
    "\n",
    "    # Move current time forward\n",
    "    current_time = end_sample\n",
    "\n",
    "# Normalize the audio to avoid clipping\n",
    "audio = audio / np.max(np.abs(audio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipy_audio(data=audio[:1500000], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbol String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pitch_class(note):\n",
    "    return librosa.midi_to_svara_h(note, Sa=root, abbr=True, octave=False, unicode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syms = [to_pitch_class(nn) for nn in nts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icm-shruti-analysis-XL3d-GDY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
